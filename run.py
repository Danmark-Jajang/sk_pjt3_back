from flask import Flask, jsonify, request, render_template
import openai
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, GPTVectorStoreIndex
import faiss
from llama_index.core import StorageContext, load_index_from_storage
from groq import Groq
from openai import OpenAI
import requests
from datetime import datetime, timedelta
import re
import json
import os
import jinja2
from flask_cors import CORS
from dotenv import load_dotenv
from kakao import kakao_bp

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# API Key ì„¤ì •

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")

os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY
os.environ['GROQ_API_KEY'] = GROQ_API_KEY

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)  # ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì ‘ê·¼ í—ˆìš©

app.config['JSON_AS_ASCII'] = False
app.register_blueprint(kakao_bp)

# index dump ì—†ì„ ë•Œ ì‹¤í–‰ì‹œí‚¤ëŠ” ì½”ë“œ
# document = SimpleDirectoryReader('./data').load_data()
# index = GPTVectorStoreIndex.from_documents(document)
# index.storage_context.persist('index_db_backup')

# ê¸°ìƒì²­ API Base URL
SHORT_URL = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst"
MID_URL = "http://apis.data.go.kr/1360000/MidFcstInfoService/getMidLandFcst"

# ì„œìš¸ ì§€ì—­ ê¸°ë³¸ ì¢Œí‘œ -> ê³ ì •ê°’ ë³€ê²½X (ì§€ì—­ì„ ì „êµ­ìœ¼ë¡œ í™•ëŒ€í•œë‹¤ë©´ ë™ì ìœ¼ë¡œ ë³€ê²½ í•„ìš”)
SEOUL_NX, SEOUL_NY = 60, 127

def get_latest_valid_base_time():
    """ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœê·¼ `base_time` ë°˜í™˜ (3ì‹œê°„ ë‹¨ìœ„) """
    now = datetime.now()
    base_date = now.strftime("%Y%m%d")

    valid_hours = [2, 5, 8, 11, 14, 17, 20, 23]
    latest_hour = max([h for h in valid_hours if h <= now.hour])
    base_time = f"{latest_hour:02d}00"

    return base_date, base_time

def fetch_short_weather(region, user_date):
    """ ë‹¨ê¸°ì˜ˆë³´ (3ì¼ ì´ë‚´ ì˜ˆë³´) ë°ì´í„° ì¡°íšŒ """
    nx, ny = SEOUL_NX, SEOUL_NY
    base_date, base_time = get_latest_valid_base_time()

    params = {
        "serviceKey": WEATHER_API_KEY,
        "numOfRows": 1000,
        "pageNo": 1,
        "dataType": "JSON",
        "base_date": base_date,
        "base_time": base_time,
        "nx": nx,
        "ny": ny
    }

    response = requests.get(SHORT_URL, params=params)
    if response.status_code == 200:
        data = response.json()
        if "response" in data and "body" in data["response"] and "items" in data["response"]["body"]:
            items = data["response"]["body"]["items"].get("item", [])
            filtered_data = [d for d in items if d["fcstDate"] == user_date]

            if filtered_data:
                weather_summary = {d["category"]: d["fcstValue"] for d in filtered_data}

                return {
                    "temperature": f"{weather_summary.get('TMP', 'N/A')}Â°C",
                    "precipitation": {
                        "0": "ì—†ìŒ", "1": "ë¹„", "2": "ë¹„/ëˆˆ", "3": "ëˆˆ"
                    }.get(weather_summary.get('PTY', "0"), "N/A"),
                    "condition": {
                        "1": "ë§‘ìŒ", "3": "êµ¬ë¦„ ë§ìŒ", "4": "íë¦¼"
                    }.get(weather_summary.get('SKY', "1"), "N/A")
                }

    return {"temperature": "ë°ì´í„° ì—†ìŒ", "precipitation": "ë°ì´í„° ì—†ìŒ", "condition": "ë°ì´í„° ì—†ìŒ"}

def fetch_mid_weather(region, user_date):
    """ ì¤‘ê¸°ì˜ˆë³´ (4~10ì¼ í›„ ì˜ˆë³´) ë°ì´í„° ì¡°íšŒ """
    now = datetime.now()
    today = now.strftime("%Y%m%d")

    date_obj = datetime.strptime(user_date, "%Y%m%d")
    days_ahead = (date_obj - now).days

    if days_ahead < 4:
        return None

    params = {
        "serviceKey": WEATHER_API_KEY,
        "numOfRows": 10,
        "pageNo": 1,
        "dataType": "JSON",
        "regId": "11B00000",
        "tmFc": today + "0600"
    }

    response = requests.get(MID_URL, params=params)
    if response.status_code == 200:
        data = response.json()
        if "response" in data and "body" in data["response"] and "items" in data["response"]["body"]:
            items = data["response"]["body"]["items"].get("item", [])
            if items:
                forecast = items[0]
                forecast_key = f"rnSt{days_ahead}Am"
                rain_prob = forecast.get(forecast_key, "N/A")

                return {
                    "temperature": "N/A (ì¤‘ê¸° ì˜ˆë³´ëŠ” ê¸°ì˜¨ ì •ë³´ ì—†ìŒ)",
                    "precipitation": f"{rain_prob}%",
                    "condition": "ë¹„ ì˜ˆë³´ ìˆìŒ" if rain_prob and int(rain_prob) > 50 else "ë§‘ìŒ"
                }

    return None

def fetch_weather(region, user_date):
    """ ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚ ì§œì— ë§ì¶° ë‹¨ê¸°ì˜ˆë³´ ë˜ëŠ” ì¤‘ê¸°ì˜ˆë³´ë¥¼ ì¡°íšŒ """
    now = datetime.now()
    days_ahead = (datetime.strptime(user_date, "%Y%m%d") - now).days

    if days_ahead >= 4:
        mid_weather = fetch_mid_weather(region, user_date)
        if mid_weather:
            return mid_weather

    return fetch_short_weather(region, user_date)


# Faiss Vector DBë¡œ ì‹¤í–‰ì‹œí‚¤ëŠ” ì½”ë“œ
# ì™œì¸ì§€ëŠ” ëª¨ë¥´ê² ì§€ë§Œ ê³„ì† ì—ëŸ¬ëœ¸, ì‚¬ìš©ê¸ˆì§€;;;;
# faiss_index = faiss.IndexFlatL2(1536)
# document = SimpleDirectoryReader('./data').load_data()
# vectorstore = FaissVectorStore(faiss_index=faiss_index)
# storage_context = StorageContext.from_defaults(vector_store=vectorstore)
# index = GPTVectorStoreIndex.from_documents(
#     document,
#     storage_context = storage_context
# )
# index.storage_context.persist('index_db_backup')


# ì´ë¯¸ ìƒì„±ëœ VectorDB ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
storage_context = StorageContext.from_defaults(persist_dir='./index_db_backup')
index    = load_index_from_storage(storage_context)
query_engine = index.as_query_engine()



client_groq = Groq(
    api_key=os.environ.get(GROQ_API_KEY)
)

# í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_region_and_keywords(text):
    # ì˜ˆì‹œ: í•œêµ­ ì£¼ìš” ë„ì‹œ ë° í‚¤ì›Œë“œ íŒ¨í„´ (í”„ë¡œì íŠ¸ì— ë§ê²Œ í™•ì¥ ê°€ëŠ¥)
    regions = ["ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ìš©ì‚°êµ¬", "ì„±ë™êµ¬", "ê´‘ì§„êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ì¤‘ë´êµ¬", "ì„±ë¶êµ¬", "ê°•ë¶êµ¬",
                "ë„ë´‰êµ¬", "ë…¸ì›êµ¬", "ì€í‰êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ë§ˆí¬êµ¬", "ì–‘ì²œêµ¬", "ê°•ì„œêµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
                  "ì˜ë“±í¬êµ¬", "ë™ì‘êµ¬", "ê´€ì•…êµ¬", "ì„œì´ˆêµ¬", "ê°•ë‚¨êµ¬", "ì†¡íŒŒêµ¬", "ê°•ë™êµ¬"]
    keywords = ["ë¬¸í™”ì‹œì„¤", "ì¶•ì œ", "ê³µì—°", "í–‰ì‚¬", "ê´€ê´‘ì§€", "ì—¬í–‰ì½”ìŠ¤", "ë ˆí¬ì¸ ", "ìˆ™ë°•", "ì‡¼í•‘", "ìŒì‹ì "]
    types = ["ê·¼ì²˜", "ì¸ê·¼", "ì£¼ë³€", "ì‚¬ëŒ ë§ì€", "ì‚¬ëŒ ì ì€", "ìœ ëª…í•œ", "ì¡°ìš©í•œ", "ì¸ê¸° ë§ì€"]

    region = next((r for r in regions if r in text), None)
    keyword = next((k for k in keywords if k in text), None)
    types = next((t for t in types if t in text), None)

    return region, keyword, types

# Groq ë‹µë³€
def tour_query_korean(query):
  res = query_engine.query(query)
  sys_prompt = f'''
ì§€ì¹¨:
- ë„ì›€ì´ ë˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•  ê²ƒ. ë‹µì„ ëª¨ë¥´ë©´ 'ì˜ ëª¨ë¥´ê² ì–´ìš”'ë¼ê³  ë§í•  ê²ƒ
- ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì œê³µëœ ë§¥ë½ì„ í™œìš©í•  ê²ƒ
- ê¸°ì¡´ ì§€ì‹ì„ í†µí•©í•˜ì—¬ ë‹µë³€ì˜ ê¹Šì´ì™€ ê´€ë ¨ì„±ì„ ë†’ì¼ ê²ƒ
- ì¶œì²˜ë¥¼ ë°í ê²ƒ
- ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•  ê²ƒ
- ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì§€ì—­ê³¼ ì¼ì¹˜í•˜ëŠ” ì§€ì—­ë§Œ ê²€ìƒ‰í•  ê²ƒ
- ì•„ë˜ ì íŒ ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰í•  ê²ƒ

ë‚´ìš©: {res}
'''

  completion = client_groq.chat.completions.create(
      model = 'llama3-8b-8192',
      messages = [
          {
              'role': 'system',
              'content': sys_prompt
          },
          {
              'role':'user',
              'content': query
          }
      ]
  )
  print('index query: ',res)
  return completion.choices[0].message.content



client_openai = OpenAI(
    api_key=os.environ.get(OPENAI_API_KEY)
)

# OpenAI ë‹µë³€
def tour_query_openai_korean(query):
  res = query_engine.query(query)
  print('index query: ',res)
  sys_prompt = f'''
ì§€ì¹¨:
- ë„ˆëŠ” ë„ì›€ë˜ëŠ” ì—¬í–‰ í”Œë˜ë„ˆì´ë‹¤.
- ë„ì›€ì´ ë˜ê³  ìì„¸í•˜ê²Œ ë‹µí•  ê²ƒ. ë‹µì„ ëª¨ë¥´ë©´ 'ì˜ ëª¨ë¥´ê² ì–´ìš”'ë¼ê³  ë§í•  ê²ƒ
- ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì œê³µëœ ë§¥ë½ì„ í™œìš©í•  ê²ƒ
- ê¸°ì¡´ ì§€ì‹ì„ í†µí•©í•˜ì—¬ ë‹µë³€ì˜ ê¹Šì´ì™€ ê´€ë ¨ì„±ì„ ë†’ì¼ ê²ƒ
- ì¶œì²˜ë¥¼ ë°í ê²ƒ
- ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•  ê²ƒ
- ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì§€ì—­ê³¼ ì¼ì¹˜í•˜ëŠ” ì§€ì—­ë§Œ ê²€ìƒ‰í•  ê²ƒ
- ì•„ë˜ ì íŒ ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰í•  ê²ƒ
ë‚´ìš©: {res}
'''
  answer = client_openai.chat.completions.create(
      model = 'gpt-4o-mini',
      messages = [
          {
              'role': 'system',
              'content': sys_prompt
          },
          {
              'role':'user',
              'content': query
          }
      ],
      temperature=0.6,
      max_tokens=500
  )
  return answer.choices[0].message.content

import re
from datetime import datetime, timedelta

def extract_date_from_query(query):
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ì—ì„œ ë‚ ì§œ(YYYYMMDD)ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    - '22ì¼'ì²˜ëŸ¼ ë‚ ì§œë§Œ ì…ë ¥í•˜ë©´ í˜„ì¬ ì—°ë„/ì›”ì„ ìë™ ì ìš©
    - 'YYYYë…„ MMì›” DDì¼' í˜•ì‹ë„ ì²˜ë¦¬ ê°€ëŠ¥
    - 'ë‚´ì¼', 'ëª¨ë ˆ', 'ì´ë²ˆ ì£¼ë§' ê°™ì€ í‘œí˜„ë„ ì²˜ë¦¬
    """
    now = datetime.now()
    current_year, current_month, current_day = now.year, now.month, now.day

    # ì •ê·œì‹ìœ¼ë¡œ 'YYYYë…„ MMì›” DDì¼' íŒ¨í„´ ì°¾ê¸°
    full_date_match = re.search(r'(\d{4})ë…„ (\d{1,2})ì›” (\d{1,2})ì¼', query)

    # '22ì¼' ê°™ì€ ë‹¨ìˆœ ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
    day_match = re.search(r'(\d{1,2})ì¼', query)

    if full_date_match:
        year, month, day = map(int, full_date_match.groups())
        return f"{year}{month:02d}{day:02d}"

    if day_match:
        day = int(day_match.group(1))
        # ì´ë¯¸ ì§€ë‚œ ë‚ ì§œë©´ ë‹¤ìŒ ë‹¬ë¡œ ì´ë™
        if day < current_day:
            if current_month == 12:
                target_date = datetime(current_year + 1, 1, day)
            else:
                target_date = datetime(current_year, current_month + 1, day)
        else:
            target_date = datetime(current_year, current_month, day)
        return target_date.strftime("%Y%m%d")

    # ìì—°ì–´ ë‚ ì§œ í‘œí˜„ ì²˜ë¦¬
    natural_dates = {
        "ë‚´ì¼": timedelta(days=1),
        "ëª¨ë ˆ": timedelta(days=2),
        "ì´ë²ˆ ì£¼ë§": timedelta(days=(5 - now.weekday()) if now.weekday() < 5 else 1),
        "ë‹¤ìŒ ì£¼ë§": timedelta(days=(12 - now.weekday()) if now.weekday() < 5 else 8),
        "ë‹¤ìŒì£¼": timedelta(days=7),
        "ë‹¤ìŒ ì£¼": timedelta(days=7),
    }

    for key, delta in natural_dates.items():
        if key in query:
            return (now + delta).strftime("%Y%m%d")

    return None  # ë‚ ì§œê°€ ì—†ëŠ” ê²½ìš°


def tour_query_openai_korean_jinja2(query):
    """ê¸°ìƒ ì •ë³´ ë°˜ì˜í•˜ì—¬ ì—¬í–‰ ì¼ì • ì¶”ì²œ """

    # ì‚¬ìš©ì ìš”ì²­ ë‚ ì§œ ì¶”ì¶œ
    user_date = extract_date_from_query(query) or datetime.now().strftime("%Y%m%d")
    today_date = datetime.now().strftime("%Y-%m-%d")
    print(f"[LOG] ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚ ì§œ: {user_date}")
    print(f"[LOG] ì˜¤ëŠ˜ ë‚ ì§œ: {today_date}")

    # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì§€ì—­, í‚¤ì›Œë“œ, ìœ í˜• ì¶”ì¶œ
    region, keyword, types = extract_region_and_keywords(query)
    print(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: ì§€ì—­={region}, í‚¤ì›Œë“œ={keyword}, ìœ í˜•={types}")

    # ë²¡í„° DBì—ì„œ ì—¬í–‰ ê´€ë ¨ ë°ì´í„° ê²€ìƒ‰ -> ì œì¼ ì¤‘ìš”í•¨
    res = query_engine.query(query)
    print(f" [ë²¡í„° DB ê²€ìƒ‰ ê²°ê³¼]: {res}")

    # í•´ë‹¹ ë‚ ì§œì˜ ê¸°ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    weather_data = fetch_weather(region if region else "ì„œìš¸", user_date)
    print(f" [ë‚ ì”¨ ë°ì´í„°]: {weather_data}")

    # ë‚ ì”¨ ìƒíƒœ ê¸°ë°˜ ì¶”ì²œ ë¡œì§
    weather_condition = weather_data["condition"]
    precipitation = weather_data["precipitation"]

    if precipitation and precipitation.endswith("%"):
        weather_impact = f"{user_date}ì—ëŠ” ê°•ìˆ˜ í™•ë¥ ì´ {precipitation}ì…ë‹ˆë‹¤."
    elif precipitation in ["ë¹„", "ë¹„/ëˆˆ", "ëˆˆ"]:
        weather_impact = "í•´ë‹¹ ë‚ ì§œì—ëŠ” ë¹„ ë˜ëŠ” ëˆˆì´ ì˜ˆìƒë©ë‹ˆë‹¤. ì‹¤ë‚´ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê² ìŠµë‹ˆë‹¤."
    elif weather_condition == "êµ¬ë¦„ ë§ìŒ" or weather_condition == "íë¦¼":
        weather_impact = "íë¦° ë‚ ì”¨ì…ë‹ˆë‹¤. ì‹¤ë‚´ì™¸ ê´€ê´‘ì§€ë¥¼ ì ì ˆíˆ ì„ì–´ ì¶”ì²œí•˜ê² ìŠµë‹ˆë‹¤."
    else:
        weather_impact = "ë§‘ì€ ë‚ ì”¨ì…ë‹ˆë‹¤! ì•¼ì™¸ í™œë™í•˜ê¸° ì¢‹ì€ ë‚ ì´ë„¤ìš”."

    # OpenAI í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê¸°ì¡´ ê²€ìƒ‰ ë°ì´í„° + ë‚ ì”¨ ë°ì´í„° ë°˜ì˜)
    sys_prompt = f"""
    ì§€ì¹¨:
    - ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today_date}ì…ë‹ˆë‹¤.
    - ë„ˆëŠ” ë„ì›€ë˜ëŠ” ì—¬í–‰ í”Œë˜ë„ˆì´ë‹¤.
    - ë„ì›€ì´ ë˜ê³  ìì„¸í•˜ê²Œ ë‹µí•  ê²ƒ. ë‹µì„ ëª¨ë¥´ë©´ 'ì˜ ëª¨ë¥´ê² ì–´ìš”'ë¼ê³  ë§í•  ê²ƒ
    - ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì œê³µëœ ë§¥ë½ì„ í™œìš©í•  ê²ƒ
    - ê¸°ì¡´ ì§€ì‹ì„ í†µí•©í•˜ì—¬ ë‹µë³€ì˜ ê¹Šì´ì™€ ê´€ë ¨ì„±ì„ ë†’ì¼ ê²ƒ
    - ì¶œì²˜ë¥¼ ë°í ê²ƒ
    - ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•  ê²ƒ
    - ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚ ì§œ({user_date})ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì¼ì • ì¶”ì²œí•  ê²ƒ.
    - í˜„ì¬ ë‚ ì”¨ ì •ë³´: {weather_data}
    - {weather_impact}
    - ê²€ìƒ‰ëœ ì—¬í–‰ ì •ë³´:
        {res}
    - ì¥ì†Œ ì´ë¦„ì€ ë°˜ë“œì‹œ **êµµê²Œ(`**`)** í‘œê¸°í•  ê²ƒ. ì˜ˆ: **ê²½ë³µê¶**, **ë‚¨ì‚°íƒ€ì›Œ**
    - ì¥ì†Œ ì´ë¦„ ì™¸ì—ëŠ” ì ˆëŒ€ **ê¸°í˜¸(`**`)**ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.
    - ê°•ì¡°ë‚˜ ë‹¤ë¥¸ í‘œí˜„ì—ì„œ `**`ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.
    - ì¶”ì²œí•œ ì¥ì†Œì—ì„œ ê°ˆ ìˆ˜ ìˆëŠ” ì—¬í–‰ ê²½ë¡œë„ ì¶”ì²œí•  ê²ƒ.
    - ì¶”ì²œ ì‹œ ì‚¬ìš©ìì˜ ì·¨í–¥ì„ ë°˜ì˜í•  ê²ƒ.
    - ì¥ì†Œì— ê¸°ë°˜í•˜ì—¬ ê·¼ì²˜ì— ê°ˆ ìˆ˜ ìˆëŠ” ì·¨í–¥ì— ë§ëŠ” ê´€ê´‘ì§€ë“¤ì„ ë¬¶ì–´ ì—¬í–‰ ê³„íšì„ ì¶”ì²œí•  ê²ƒ.
    - ì‚¬ìš©ìì˜ ì·¨í–¥ì„ ë°˜ì˜í•˜ì§€ ì•Šì„ ë•Œì—ëŠ” ìœ ëª…í•œ ì¥ì†Œ ìœ„ì£¼ë¡œ ì¶”ì²œí•  ê²ƒ.
    - ì§‘ì¤‘ë¥ ì´ ë†’ì€ ì§€ì—­ì€ ì‚¬ëŒì´ ë§ê³  ìœ ëª…í•œ ê´€ê´‘ì§€ë¡œ íŒë³„í•  ê²ƒ
    - ì§‘ì¤‘ë¥ ì´ ë‚®ì€ ì§€ì—­ì€ ì‚¬ëŒì´ ì ê³  ëœ ì•Œë ¤ì§„ ê´€ê´‘ì§€ë¡œ íŒë³„í•  ê²ƒ
    - ì‚¬ìš©ìì˜ ì·¨í–¥ì„ ë°˜ì˜í•  ë•Œ ì‚¬ëŒì´ ë§ê±°ë‚˜ ì ì€ ê´€ê´‘ì§€ì—ì„œ ë”°ë¼ì˜¬ ìˆ˜ ìˆëŠ” ìƒí™©ì„ ê³ ë ¤í•  ê²ƒ
    - ì§‘ì¤‘ë¥ ì´ ë†’ì€ ì§€ì—­ì´ë¼ë„ ê´€ê´‘ì§€ì˜ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ìƒí™©ì„ íŒë‹¨í•  ê²ƒ
    - ì•„ë˜ ì íŒ ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰í•  ê²ƒ
    ì£¼ìš”ë‚´ìš©: {region if region is not None else ""}, {keyword if keyword is not None else ""}, {types if types is not None else ""}
    ë‚´ìš©: {res}
    """

    # OpenAI GPT-4o-mini í˜¸ì¶œ
    answer = client_openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": query}
        ],
        temperature=0.6,
        max_tokens=1000
    )

    return answer.choices[0].message.content



# ì´ë¯¸ì§€ ìƒì„±
def create_image(prompt):
  summary = summarize_query_openai(prompt)
  img =  client_openai.images.generate(
    model = 'dall-e-3',
    prompt = summary,
    size = '1024x1024',
    quality = 'standard',
    n=1
  )
  return img.data[0].url

# ë‚´ìš©ìš”ì•½
def summarize_query_openai(query):
  sys_prompt = f"""
ì§€ì¹¨
- ë„ˆëŠ” ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë§Œ ë½‘ì•„ì„œ ìš”ì•½í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ agentì´ë‹¤
- ìš”ì•½ëœ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ 100ì ì´ë‚´ì—¬ì•¼ í•œë‹¤
- ì—¬í–‰ ê´€ë ¨ëœ í‚¤ì›Œë“œë¡œ ë½‘ì•„ì•¼ í•œë‹¤
- ê´€ê´‘ì§€ì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œë¡œ ë½‘ì•„ì•¼ í•œë‹¤
"""
  summary = client_openai.chat.completions.create(
    model = 'gpt-4o-mini',
      messages = [
          {
              'role': 'system',
              'content': sys_prompt
          },
          {
              'role':'user',
              'content': query
          }
      ],
      temperature=0.8,
      max_tokens=100
  )
  return summary.choices[0].message.content

# Groq ì±—ë´‡ query
# ì“°ì§€ë§ˆì„¸ìš”@@@@@
# @app.route('/api/post/groq', methods=['POST'])
# def query_groq_post():
#   request_data = request.get_json()
#   query = request_data["query"]
#   return json.dumps({'query':tour_query_korean(query)}, ensure_ascii=False)

# OpenAI ì±—ë´‡ query
# ì“°ì§€ë§ˆì„¸ìš”@@@@@
@app.route('/api/post/openai', methods=['POST'])
def query_openai_post():
  request_data = request.get_json()
  query = request_data["query"]
  return json.dumps({'query':tour_query_openai_korean(query)}, ensure_ascii=False)

# OpenAI ì±—ë´‡ query V2
@app.route('/api/post/openai/v2', methods=['POST'])
def query_openai_post_v2():
  request_data = request.get_json()
  query = request_data["query"]
  return json.dumps({'query':tour_query_openai_korean_jinja2(query)}, ensure_ascii=False)

# Dall-e-3 í¬ìŠ¤í„° ìƒì„±
@app.route('/api/post/openai/poster', methods=['POST'])
def query_openai_poster():
  request_data = request.get_json()
  query = request_data['query']
  return json.dumps({'images':create_image(query)})

# Flask ì‹¤í–‰
if __name__ == '__main__':
  app.run(debug=True)